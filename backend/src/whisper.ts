import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import { Transcript, TranscriptSegment } from './types';
import { AppError } from './errors';
import { downloadYouTubeAudio } from './audio';
import { getCachedTranscript, cacheTranscript } from './cache';

const TEMP_DIR = path.join(process.cwd(), 'temp');

// Ensure temp directory exists
if (!fs.existsSync(TEMP_DIR)) {
  fs.mkdirSync(TEMP_DIR, { recursive: true });
}


/**
 * Transcribe audio using OpenAI Whisper API
 */
export async function transcribeWithWhisper(
  audioPath: string,
  apiKey: string,
  language: string = 'pt'
): Promise<Transcript> {
  const client = new OpenAI({ apiKey });

  try {
    // Read audio file
    const audioFile = fs.createReadStream(audioPath);
    
    // Call Whisper API with verbose_json response format to get timestamps
    const transcription = await client.audio.transcriptions.create({
      file: audioFile as any,
      model: 'whisper-1',
      language: language === 'pt' ? 'pt' : language,
      response_format: 'verbose_json',
      timestamp_granularities: ['segment'],
    });

    // Parse the segments from Whisper response
    const segments: TranscriptSegment[] = [];
    
    if ('segments' in transcription && Array.isArray(transcription.segments)) {
      for (const segment of transcription.segments) {
        segments.push({
          text: segment.text,
          offset: segment.start,
          duration: segment.end - segment.start,
        });
      }
    } else if ('text' in transcription) {
      // Fallback if no segments are provided
      segments.push({
        text: transcription.text as string,
        offset: 0,
        duration: 0,
      });
    }

    return {
      videoId: path.basename(audioPath, path.extname(audioPath)),
      language: transcription.language || language,
      segments,
      isAutoGenerated: false, // Whisper transcriptions are not auto-generated
    };
  } catch (error: any) {
    if (error.response?.status === 413) {
      throw new AppError({
        code: 'AUDIO_TOO_LARGE' as any,
        message: 'Audio file is too large for Whisper API',
        userMessage: 'Arquivo de áudio muito grande (limite: 25MB)',
        suggestions: [
          'Tente com um vídeo mais curto',
          'O limite do Whisper API é 25MB',
        ],
        httpStatus: 413,
      });
    }
    throw error;
  }
}

/**
 * Main function to get transcript using Whisper
 * This is called when YouTube subtitles are not available
 */
export async function getTranscriptWithWhisper(
  videoId: string,
  apiKey: string,
  language: string = 'pt'
): Promise<Transcript> {
  // Check cache first
  const cached = getCachedTranscript(videoId, language);
  if (cached) {
    console.log(`[Whisper] Using cached transcript for ${videoId}`);
    return cached.transcript;
  }

  let audioPath: string | null = null;
  
  try {
    // Step 1: Download audio from YouTube
    console.log(`[Whisper] Downloading audio for video ${videoId}...`);
    audioPath = await downloadYouTubeAudio(videoId, 3600); // Max 1 hour for Whisper
    
    // Step 2: Transcribe with Whisper
    console.log(`[Whisper] Transcribing audio with Whisper API...`);
    const transcript = await transcribeWithWhisper(audioPath, apiKey, language);
    
    // Update videoId to match the input
    transcript.videoId = videoId;
    
    // Cache the transcript
    cacheTranscript(videoId, language, transcript, 'whisper');
    
    return transcript;
  } finally {
    // Clean up temporary audio file
    if (audioPath && fs.existsSync(audioPath)) {
      fs.unlinkSync(audioPath);
    }
  }
}

/**
 * Alternative: Transcribe from direct URL (if supported)
 * Some services allow direct URL transcription
 */
export async function transcribeFromUrl(
  videoUrl: string,
  apiKey: string,
  language: string = 'pt'
): Promise<Transcript> {
  const client = new OpenAI({ apiKey });

  try {
    // Note: OpenAI Whisper doesn't directly support URLs
    // This is a placeholder for when/if they add this feature
    // Or you can use a service that downloads and processes
    
    throw new AppError({
      code: 'URL_TRANSCRIPTION_NOT_SUPPORTED' as any,
      message: 'Direct URL transcription not supported',
      userMessage: 'Transcrição direta de URL não suportada',
      suggestions: [
        'Use o método de download de áudio',
        'Ou forneça um arquivo de áudio local',
      ],
      httpStatus: 501,
    });
  } catch (error) {
    throw error;
  }
}

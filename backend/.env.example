# OpenAI API Key (only needed for cloud mode, not for local mode)
OPENAI_API_KEY=your_openai_api_key_here

# Server port
PORT=8000

# Local mode configuration (no API keys required)
# Whisper server URL (local faster-whisper server)
WHISPER_SERVER_URL=http://localhost:5000

# Ollama server URL
OLLAMA_URL=http://localhost:11434

# Ollama model to use (llama3.2, mistral, llama3.1, phi3, etc.)
OLLAMA_MODEL=llama3.2
